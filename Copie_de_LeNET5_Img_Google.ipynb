{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Basso42/Basso42/blob/main/Copie_de_LeNET5_Img_Google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jhyx6nsmAHTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75fe9c98-7708-47f6-8598-509db8904674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "!unzip /content/drive/MyDrive/bdappv/bdappv.zip > /dev/null\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M7reAynk9i32"
      },
      "outputs": [],
      "source": [
        "sys.path.insert(0,'/content/drive/My Drive/statapps-main/src/') #permet de relocaliser le wd pour importer code\n",
        "#from src.dataloader import *\n",
        "from dataloader import *\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSUFa9gd9i36"
      },
      "source": [
        "# Import des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_wrMV6L9i38"
      },
      "source": [
        "Terminologie:\n",
        "* 1 epoch = un forward et un backward pass sur les individus tirés\n",
        "* batch size = nombre d'individus de l'échantillon d'apprentissage dans un forward/backward pass. Plus le batck size est élevé, plus il faut de mémoire\n",
        "* number of iterations = nombre de passes, chaque pass utilisant [batch size] number of examples. \n",
        "  1 pass = 1 forward pass + 1 backward pass (we do not count the forward pass and backward pass as two different passes).\n",
        "\n",
        "Exemple: si j'ai 1000 individus dans l'échantillon d'apprentissage, et que batch_size=500.\n",
        "* 1st pass: 500 individus tirés pour le forward\n",
        "* 2nd pass: 500 individus tirés pour le backward\n",
        "\n",
        "Donc, il faut 2 itérations pour réaliser un epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Oe9XjFcB9i39"
      },
      "outputs": [],
      "source": [
        "# label_attribution=LabelAttribution(path_image_google=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\", \n",
        "#                                    path_mask_google='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/mask/',\n",
        "#                                    path_metadata='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/metadata.csv',\n",
        "#                                    colonne_identifiant='identifiant',\n",
        "#                                    path_export_train_test=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/statapps\",\n",
        "#                                    path_image_ign='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/ign/img',\n",
        "#                                    path_mask_ign='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/ign/mask/',\n",
        "#                                    use_img_google=True,\n",
        "#                                    use_img_ign=False\n",
        "#                                     )\n",
        "\n",
        "label_attribution=LabelAttribution(path_image_google='/content/bdappv/google/img', \n",
        "                                   path_mask_google='/content/bdappv/google/mask',\n",
        "                                   path_metadata='/content/bdappv/metadata.csv',\n",
        "                                   colonne_identifiant='identifiant',\n",
        "                                   path_export_train_test='/content/bdappv/google',\n",
        "                                   path_image_ign='/content/bdappv/ign/img',\n",
        "                                   path_mask_ign='/content/bdappv/ign/img',\n",
        "                                   use_img_google=True,\n",
        "                                   use_img_ign=False\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikm6aoxMKC3w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dirs = os.listdir('/content/bdappv/google/img')\n",
        "test=[file.replace('.png','') for file in dirs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEFpabmI9i3-"
      },
      "outputs": [],
      "source": [
        "label_attribution.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGAdVdA39i3-"
      },
      "source": [
        "Le LeNET5 a été conçu pour prendre en entrée des images de dimension 28*28. On passe donc les images 400 x 400 en 28 x 28. On convertit ensuite ces dernières en tenseurs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrW-sF5N9i3_"
      },
      "outputs": [],
      "source": [
        "# path_train=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/statapps/train_data.csv\"\n",
        "# path_test=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/statapps/test_data.csv\"\n",
        "\n",
        "# transformed_train_dataset  = CustomImageDataset(path_train,\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\", transform=transforms.Compose([\n",
        "#                                                transforms.Resize(28),\n",
        "#                                                transforms.ToTensor()\n",
        "#                                            ]))\n",
        "# transformed_test_dataset = CustomImageDataset(path_test,\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\",\n",
        "#                                                 transform=transforms.Compose([\n",
        "#                                                transforms.Resize(28),\n",
        "#                                                transforms.ToTensor(),\n",
        "#                                            ]))\n",
        "\n",
        "\n",
        "path_train='/content/bdappv/google/train_data.csv'\n",
        "path_test='/content/bdappv/google/test_data.csv'\n",
        "\n",
        "transformed_train_dataset  = CustomImageDataset(path_train,'/content/bdappv/google/img', transform=transforms.Compose([\n",
        "                                               transforms.Resize(28),\n",
        "                                               transforms.ToTensor()\n",
        "                                           ]))\n",
        "transformed_test_dataset = CustomImageDataset(path_test,\"/content/bdappv/google/img\",\n",
        "                                                transform=transforms.Compose([\n",
        "                                               transforms.Resize(28),\n",
        "                                               transforms.ToTensor(),\n",
        "                                           ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjdRTdfO9i3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f3a6c5-45d0-497e-a128-f54c540528d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre d'images dans le train: 23045\n",
            "Nombre d'images dans le test: 5762\n"
          ]
        }
      ],
      "source": [
        "print(\"Nombre d'images dans le train: {}\".format(transformed_train_dataset.__len__()))\n",
        "print(\"Nombre d'images dans le test: {}\".format(transformed_test_dataset.__len__()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcZguti19i4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78bc2346-da0b-4554-cd7c-3b127ddf4333"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2118, 0.1020, 0.1176,  ..., 0.4196, 0.4000, 0.4353],\n",
              "         [0.1882, 0.1412, 0.1294,  ..., 0.4353, 0.4588, 0.5412],\n",
              "         [0.2431, 0.2196, 0.2275,  ..., 0.4549, 0.4157, 0.2392],\n",
              "         ...,\n",
              "         [0.2392, 0.1255, 0.1020,  ..., 0.1137, 0.1137, 0.1255],\n",
              "         [0.2706, 0.2431, 0.2588,  ..., 0.1020, 0.0980, 0.1137],\n",
              "         [0.2980, 0.3412, 0.3843,  ..., 0.1647, 0.1843, 0.1647]],\n",
              "\n",
              "        [[0.2392, 0.1255, 0.1529,  ..., 0.4275, 0.4392, 0.4784],\n",
              "         [0.2196, 0.1608, 0.1529,  ..., 0.4392, 0.4706, 0.5647],\n",
              "         [0.2902, 0.2549, 0.2706,  ..., 0.4588, 0.4275, 0.2745],\n",
              "         ...,\n",
              "         [0.3098, 0.1569, 0.1137,  ..., 0.1176, 0.1098, 0.1216],\n",
              "         [0.3294, 0.2471, 0.2667,  ..., 0.1059, 0.0980, 0.1098],\n",
              "         [0.3451, 0.3490, 0.3922,  ..., 0.1647, 0.1843, 0.1647]],\n",
              "\n",
              "        [[0.1882, 0.0941, 0.1098,  ..., 0.3922, 0.3569, 0.4039],\n",
              "         [0.1608, 0.1216, 0.1098,  ..., 0.4078, 0.4353, 0.5412],\n",
              "         [0.2078, 0.1882, 0.1961,  ..., 0.4314, 0.3922, 0.2392],\n",
              "         ...,\n",
              "         [0.2078, 0.1137, 0.0863,  ..., 0.1098, 0.1176, 0.1333],\n",
              "         [0.2510, 0.2157, 0.2235,  ..., 0.0902, 0.0941, 0.1137],\n",
              "         [0.2824, 0.3255, 0.3686,  ..., 0.1529, 0.1765, 0.1608]]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "transformed_train_dataset.__getitem__(0)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy_1Gm689i4B"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(transformed_train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(transformed_test_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66c5In3A9i4C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "b72dd73a-1233-454e-c50d-1adf8abb556e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 3, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 1\n"
          ]
        }
      ],
      "source": [
        "# Display image and label.\n",
        "\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "#print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[2].squeeze()\n",
        "label = train_labels[2]\n",
        "plt.imshow(img.T)\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYWWuU4D9i4C"
      },
      "source": [
        "On normalise aussi les images: pour chaque chaque channel d'un tenseur, on met la moyenne à 0 et la variance à 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWq0LKAW9i4C"
      },
      "source": [
        "output[channel] = (input[channel] - mean[channel]) / std[channel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a8e-5_L9i4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4067454-6246-4321-ddff-a5129fc875a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moyenne par channel: tensor([0.3408, 0.3459, 0.2928])\n",
            "Ecart-type par channel: tensor([0.1462, 0.1297, 0.1243])\n"
          ]
        }
      ],
      "source": [
        "mean, std = mean_std(train_dataloader)\n",
        "print(\"Moyenne par channel: {}\".format(mean))\n",
        "print(\"Ecart-type par channel: {}\".format(std))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv9X3yWr9i4D"
      },
      "source": [
        "Comme on a utilisé des batches, les moyennes et écart-types calculés précédemment sont faux. On utilise, le code suivant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYFi0f6L9i4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc339e9-efcc-4a5d-b03d-827759f895f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moyenne par channel: tensor([0.3493, 0.3567, 0.3072])\n",
            "Ecart-type par channel: tensor([0.1662, 0.1475, 0.1457])\n"
          ]
        }
      ],
      "source": [
        "mean, std = batch_mean_and_sd(train_dataloader)\n",
        "print(\"Moyenne par channel: {}\".format(mean))\n",
        "print(\"Ecart-type par channel: {}\".format(std))\n",
        "\n",
        "#prend 2 min de temps à tourner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voAFIRa3H9Jk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969d8ba7-8ba0-4108-91d2-9bea3f15d7e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moyenne par channel: tensor([0.3499, 0.3576, 0.3080])\n",
            "Ecart-type par channel: tensor([0.1675, 0.1488, 0.1472])\n"
          ]
        }
      ],
      "source": [
        "mean, std = batch_mean_and_sd(test_dataloader)\n",
        "print(\"Moyenne par channel: {}\".format(mean))\n",
        "print(\"Ecart-type par channel: {}\".format(std))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnEDf1QS9i4E"
      },
      "source": [
        "On normalise les données. On ajoute aussi des rotations horizontales aléatoires. Avec probabilité 0.5, l'image est retournée."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRCqV0dy9i4E"
      },
      "outputs": [],
      "source": [
        "normalized_train_dataset  = CustomImageDataset(path_train,'/content/bdappv/ign/img', transform=transforms.Compose([\n",
        "                                               transforms.Resize(28),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize(mean = [0.3493,0.3566,0.3072],\n",
        "                                                                    std= [0.1662,0.1475,0.1456]),\n",
        "                                               transforms.RandomHorizontalFlip(),\n",
        "                                           ]))\n",
        "\n",
        "normalized_test_dataset  = CustomImageDataset(path_test,'/content/bdappv/ign/img', transform=transforms.Compose([\n",
        "                                               transforms.Resize(28),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize(mean = [0.3493,0.3566,0.3072],\n",
        "                                                                    std= [0.1662,0.1475,0.1456]),\n",
        "                                               transforms.RandomHorizontalFlip(),\n",
        "                                           ]))\n",
        "\n",
        "train_dataloader = DataLoader(normalized_train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(normalized_test_dataset, batch_size=64, shuffle=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}